{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os \n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "path = '/content/drive/MyDrive/Hepsiburada Sentiment'\n",
    "\n",
    "data_path = path + '/' + os.listdir(path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "data.head()\n",
    "\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Rating'].values\n",
    "X = df['Review'].values     \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal length 243497\n",
      "unique length 214662\n"
     ]
    }
   ],
   "source": [
    "print('normal length', len(X))\n",
    "print('unique length', len(set(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_sequences is used to convert text to a list of integer sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X_train_tokenized = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokenized = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "çok 1\n",
      "bir 2\n",
      "ve 3\n",
      "ürün 4\n",
      "bu 5\n",
      "iyi 6\n",
      "güzel 7\n",
      "için 8\n",
      "tavsiye 9\n",
      "ederim 10\n"
     ]
    }
   ],
   "source": [
    "keys = list(tokenizer.word_index.keys())[:10]\n",
    "values = list(tokenizer.word_index.values())[:10]\n",
    "\n",
    "for key, value in zip(keys, values):\n",
    "    print(key, value)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 25, 17, ..., 18, 39, 21])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = np.array([len(token) for token in X_train_tokenized + X_test_tokenized])\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 20.744703220162876\n",
      "std 19.533556911847846\n",
      "argmax 234980\n"
     ]
    }
   ],
   "source": [
    "print('mean', num_tokens.mean())\n",
    "print('std', num_tokens.std())\n",
    "print('argmax', num_tokens.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Özellikle bu kısma yazıyorum iyice okuyunuz,cihazın hızı çok iyi.Isınma normal boyutlarda.Kamerası elinizi sabit tutarsanız ve gündüz çok net gece ise çok net çekmez.Görüntülü konuşma özelliği yok ancak uygulama ile olur,anten çekimi gayet iyi.Parmak izi okuyucusu gayet hızlı bazen tuşu silmenizi istiyor ve okuyamıyor kirden vs...Ön kamera da tatmin edici,çekim esnasında ekran beyaz ışık vererek flaş görevi görür.Batarya bana 1 hafta gidiyor sık kullanımda ise 2-3 gün gidiyor.Hızlı şarj 1 saatte doluyor , şekilleri ele oturuyor ve şık bir görüntü var.Telefonu aldığım gün gittim ve ilk girdiğim yerden ekran koruyucu ve kılıf buldum.Kulaklık sesi çok net ve yüksek ancak kendi hoparlörü biraz zayıf sesi.Ekrana bakarken açık kalma özelliği yok.Diğer akıllı cihaz özellikleri %90 ı bu cihazda mevcut.Güç tasarrufu 2 ayrı modu var ve çok başarılı çalışıyor.4gb ram var genelde yarısı boş kalıyor.Bir de yeni cihazların çoğu titreşimi az ve sesi de az çıkıyor.Bu cihaz da içine dahil...Bu cihazlar güncelleme almaz ve rom bulunmuyormuş.Benim için güncelleme sorun olmaz -cihaz parasına göre s serisi ile yarışıyor çünkü.Biraz metal olmasından dolayı elden kolay kaysada duruşu ve gösterişi iyidir.Çift flaşı var arkada.Kısaca şöyle ki bu fiyata bu ürün alınır.5 aydır kullanıyorum kasma donma felan zaten olmaz,bataryası iyi,şekli iyi,özellikler de iyi....En büyük kafa karıştıran soru şu ki hadi cihaz arıza yaptı veya düştü ekranı kırıldı.Bunun bir servisi var,ithalatçı garantisi de var.Cihazın adı sanı belli...Parça bulanmaz tamir olmaz derseniz size kalmış.Zaten normal bir cihazı da düşürseniz farkedermi?.Güncelleme almaz diyorlar bu konuda düşünebilirsiniz.S serisi cihazlarla hızını kıyaslarsınız ama güncelleme ile araya fark koymuşlar.İki katı fiyata satılan cihazla farkı olmasa zaten olmaz değil mi?Almayı düşünenler başka bir cihazla kıyas yapacaksa yine  7pro veya 9 baksınlar.C5 pro da biraz boyutu kısa ve kibar....Sonuçta ömürlük değil alın fazla düşünmeyin'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((X_train, X_test))[num_tokens.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token = int(num_tokens.mean() + (2 * num_tokens.std()))\n",
    "max_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597982726686571"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.95 means that %95 of the data has less than max_token number of words\n",
    "# %5 can be neglected \n",
    "\n",
    "(num_tokens < max_token).sum() / len(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194797, 59)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad_sequences is used to make all the sentences the same length\n",
    "\n",
    "X_train_tokenized_pad = pad_sequences(X_train_tokenized, maxlen=max_token)\n",
    "X_test_tokenized_pad = pad_sequences(X_test_tokenized, maxlen=max_token)\n",
    "\n",
    "X_train_tokenized_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86, 32, 14, 7, 2, 4, 3294, 416]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,   86,   32,   14,    7,\n",
       "          2,    4, 3294,  416])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized_pad[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fiyatına göre gayet güzel bir ürün ışıkta güçlü'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "inversed_word_idex = dict(zip(word_index.values(), word_index.keys()))\n",
    "\n",
    "def show_text_from_tokens(tokens):\n",
    "\n",
    "  words = [inversed_word_idex[token] for token in tokens if token !=0]\n",
    "  return ' '.join(words)\n",
    "\n",
    "show_text_from_tokens(X_train_tokenized_pad[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?Embedding\n",
    "\"\"\"\n",
    "Init signature:\n",
    "Embedding(\n",
    "    input_dim, => is used to determine the size of the vocabulary.\n",
    "    output_dim, => is used to determine the size of the embedding vectors.\n",
    "    embeddings_initializer='uniform', => is used to initialize the embedding matrix.\n",
    "    embeddings_regularizer=None, => is used to apply regularization to the embedding matrix.\n",
    "    activity_regularizer=None,  => is used to apply regularization to the output of the layer.\n",
    "    embeddings_constraint=None, => is used to apply constraints to the embedding matrix.\n",
    "    mask_zero=False, => is used to specify whether or not the input value 0 is a special \"padding\" value that should be masked out.\n",
    "    input_length=None, => is used to specify the length of input sequences.\n",
    "    sparse=False, => is used to specify whether or not the input is sparse.\n",
    "    **kwargs,\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# ?GRU\n",
    "\"\"\"\n",
    "Init signature:\n",
    "GRU(\n",
    "    units, => is used to determine the output size of the GRU layer.\n",
    "    activation='tanh', => is used to determine the activation function.\n",
    "    recurrent_activation='sigmoid', => is used to determine the activation function for the recurrent step.\n",
    "    use_bias=True, => is used to determine whether or not a bias vector will be used.\n",
    "    kernel_initializer='glorot_uniform', => is used to initialize the kernel weights matrix.\n",
    "    recurrent_initializer='orthogonal', => is used to initialize the recurrent weights matrix.\n",
    "    bias_initializer='zeros', => is used to initialize the bias vector.\n",
    "    kernel_regularizer=None, => is used to apply regularization to the kernel weights matrix.\n",
    "    recurrent_regularizer=None, => is used to apply regularization to the recurrent weights matrix.\n",
    "    bias_regularizer=None, => is used to apply regularization to the bias vector.\n",
    "    activity_regularizer=None, => is used to apply regularization to the output of the layer.\n",
    "    kernel_constraint=None, => is used to apply constraints to the kernel weights matrix.\n",
    "    recurrent_constraint=None, => is used to apply constraints to the recurrent weights matrix.\n",
    "    bias_constraint=None, => is used to apply constraints to the bias vector. \n",
    "    dropout=0.0, => is used to specify the dropout rate for the input units. \n",
    "    recurrent_dropout=0.0, => is used to specify the dropout rate for the recurrent units.\n",
    "    return_sequences=False, => is used to specify whether or not the output of the layer will be a sequence. \n",
    "    return_state=False, => is used to specify whether or not the last state will be returned in addition to the output.\n",
    "    go_backwards=False, => is used to specify the direction of the input sequence.\n",
    "    stateful=False, => is used to specify whether or not the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n",
    "    unroll=False, => is used to specify whether or not the network will be unrolled.\n",
    "    time_major=False, => is used to specify whether the first dimension represents the time steps. \n",
    "    reset_after=True, => is used to specify whether the reset gate is applied after or before the matrix multiplication.\n",
    "...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 59, 50)            500000    \n",
      "                                                                 \n",
      " gru_18 (GRU)                (None, 59, 16)            3264      \n",
      "                                                                 \n",
      " gru_19 (GRU)                (None, 59, 8)             624       \n",
      "                                                                 \n",
      " gru_20 (GRU)                (None, 4)                 168       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 504061 (1.92 MB)\n",
      "Trainable params: 504061 (1.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(\n",
    "    input_dim=10000,\n",
    "    output_dim=50,\n",
    "    input_length=59\n",
    "))\n",
    "\n",
    "model.add(GRU(units=16, activation='tanh', return_sequences=True))\n",
    "model.add(GRU(units=8, activation='tanh', return_sequences=True))\n",
    "model.add(GRU(units=4, activation='tanh', return_sequences=False))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "6088/6088 [==============================] - 397s 64ms/step - loss: 0.1467 - accuracy: 0.9569\n",
      "Epoch 2/2\n",
      "6088/6088 [==============================] - 392s 64ms/step - loss: 0.0764 - accuracy: 0.9738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22604a558d0>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tokenized_pad, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1522/1522 [==============================] - 18s 11ms/step - loss: 0.0827 - accuracy: 0.9712\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test_tokenized_pad, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1522/1522 [==============================] - 18s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test_tokenized_pad)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 0.0, 1, 1]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [1 if value >=0.5 else 0.0 for value in predicted]\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1506,  1107],\n",
       "       [  294, 45793]], dtype=int64)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9712320328542094"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
